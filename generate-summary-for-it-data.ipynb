{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7724489,"sourceType":"datasetVersion","datasetId":4512622}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## install dependancies","metadata":{}},{"cell_type":"code","source":"# install Hugging Face Libraries\n!pip install peft\n!pip install transformers datasets accelerate evaluate bitsandbytes loralib --upgrade --quiet\n# install additional dependencies needed for training\n!pip install rouge-score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading data","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"ANWAR101/youtube-cnn\")","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:22.733256Z","iopub.execute_input":"2024-03-04T22:27:22.733617Z","iopub.status.idle":"2024-03-04T22:27:25.863085Z","shell.execute_reply.started":"2024-03-04T22:27:22.733587Z","shell.execute_reply":"2024-03-04T22:27:25.861764Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"ccdv/cnn_dailymail\" , \"3.0.0\")","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:25.865914Z","iopub.execute_input":"2024-03-04T22:27:25.866957Z","iopub.status.idle":"2024-03-04T22:27:27.219062Z","shell.execute_reply.started":"2024-03-04T22:27:25.866892Z","shell.execute_reply":"2024-03-04T22:27:27.217813Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for ccdv/cnn_dailymail contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ccdv/cnn_dailymail\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"ds = ds.remove_columns('Unnamed: 0')","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:27.220502Z","iopub.execute_input":"2024-03-04T22:27:27.222744Z","iopub.status.idle":"2024-03-04T22:27:27.232795Z","shell.execute_reply.started":"2024-03-04T22:27:27.222704Z","shell.execute_reply":"2024-03-04T22:27:27.231630Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ds = ds.shuffle(seed = 42)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:27.235485Z","iopub.execute_input":"2024-03-04T22:27:27.235824Z","iopub.status.idle":"2024-03-04T22:27:27.248140Z","shell.execute_reply.started":"2024-03-04T22:27:27.235795Z","shell.execute_reply":"2024-03-04T22:27:27.247168Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ds['train'] ","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:27.249404Z","iopub.execute_input":"2024-03-04T22:27:27.250236Z","iopub.status.idle":"2024-03-04T22:27:27.256748Z","shell.execute_reply.started":"2024-03-04T22:27:27.250212Z","shell.execute_reply":"2024-03-04T22:27:27.255832Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'summary'],\n    num_rows: 16730\n})"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import concatenate_datasets\nimport random \nrandom.seed(42)\n\ndataset[\"train\"] = dataset[\"train\"].rename_column('article' , 'text')\ndataset[\"train\"] = dataset[\"train\"].rename_column('highlights' , 'summary')\ndataset[\"train\"] = dataset[\"train\"].remove_columns('id')","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:27.257822Z","iopub.execute_input":"2024-03-04T22:27:27.258139Z","iopub.status.idle":"2024-03-04T22:27:27.277552Z","shell.execute_reply.started":"2024-03-04T22:27:27.258113Z","shell.execute_reply":"2024-03-04T22:27:27.276714Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset[\"validation\"] = dataset[\"validation\"].rename_column('article' , 'text')\ndataset[\"validation\"] = dataset[\"validation\"].rename_column('highlights' , 'summary')\ndataset[\"validation\"] = dataset[\"validation\"].remove_columns('id')","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:27.278512Z","iopub.execute_input":"2024-03-04T22:27:27.278759Z","iopub.status.idle":"2024-03-04T22:27:27.288450Z","shell.execute_reply.started":"2024-03-04T22:27:27.278737Z","shell.execute_reply":"2024-03-04T22:27:27.287294Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_ds = concatenate_datasets([ds['train'] , dataset[\"train\"].select(random.sample(range(len(ds['train'])), 5000))])\nval_ds = concatenate_datasets([ds['validation'] , dataset[\"validation\"].select(random.sample(range(len(ds['validation'])), 500))])","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:27.289599Z","iopub.execute_input":"2024-03-04T22:27:27.289868Z","iopub.status.idle":"2024-03-04T22:27:27.343452Z","shell.execute_reply.started":"2024-03-04T22:27:27.289845Z","shell.execute_reply":"2024-03-04T22:27:27.342577Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict\ndataset = DatasetDict({\n    'train': train_ds , \n    'validation': val_ds\n})\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:27.344553Z","iopub.execute_input":"2024-03-04T22:27:27.344814Z","iopub.status.idle":"2024-03-04T22:27:27.351061Z","shell.execute_reply.started":"2024-03-04T22:27:27.344792Z","shell.execute_reply":"2024-03-04T22:27:27.350229Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 21730\n    })\n    validation: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 2750\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Convert text to text to token IDs","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_id=\"facebook/bart-base\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:27.740393Z","iopub.execute_input":"2024-03-04T22:27:27.741483Z","iopub.status.idle":"2024-03-04T22:27:30.964241Z","shell.execute_reply.started":"2024-03-04T22:27:27.741440Z","shell.execute_reply":"2024-03-04T22:27:30.963384Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"max_input_length = 1024\nmax_target_length = 600\n\n\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"text\"],\n        max_length=max_input_length,\n        truncation=True,\n    )\n    labels = tokenizer(\n        examples[\"summary\"], max_length=max_target_length, truncation=True\n    )\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=ds['train'].column_names)\nprint(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:30.966024Z","iopub.execute_input":"2024-03-04T22:27:30.966568Z","iopub.status.idle":"2024-03-04T22:27:31.034428Z","shell.execute_reply.started":"2024-03-04T22:27:30.966540Z","shell.execute_reply":"2024-03-04T22:27:31.033524Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Fine-Tune with LoRA","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\nimport torch\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:31.035516Z","iopub.execute_input":"2024-03-04T22:27:31.035769Z","iopub.status.idle":"2024-03-04T22:27:33.132047Z","shell.execute_reply.started":"2024-03-04T22:27:31.035747Z","shell.execute_reply":"2024-03-04T22:27:33.130968Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType\n\n# Define LoRA Config\nlora_config = LoraConfig(\n r = 18,\n lora_alpha = 8,\n target_modules=[\"q_proj\", \"v_proj\"],\n lora_dropout=0.05,\n bias=\"none\",\n task_type=TaskType.SEQ_2_SEQ_LM\n)\n\n\n# prepare int-8 model for training\nmodel = prepare_model_for_int8_training(model)\n\n# add LoRA adaptor\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:33.134073Z","iopub.execute_input":"2024-03-04T22:27:33.134559Z","iopub.status.idle":"2024-03-04T22:27:33.288685Z","shell.execute_reply.started":"2024-03-04T22:27:33.134532Z","shell.execute_reply":"2024-03-04T22:27:33.287710Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"trainable params: 995,328 || all params: 140,415,744 || trainable%: 0.7088435895051769\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:145: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer,model=model)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:33.290046Z","iopub.execute_input":"2024-03-04T22:27:33.290297Z","iopub.status.idle":"2024-03-04T22:27:36.083041Z","shell.execute_reply.started":"2024-03-04T22:27:33.290276Z","shell.execute_reply":"2024-03-04T22:27:36.082206Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"2024-03-04 22:27:34.166223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-04 22:27:34.166278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-04 22:27:34.167768: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token = \"\")","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:36.084477Z","iopub.execute_input":"2024-03-04T22:27:36.085034Z","iopub.status.idle":"2024-03-04T22:27:36.191794Z","shell.execute_reply.started":"2024-03-04T22:27:36.085007Z","shell.execute_reply":"2024-03-04T22:27:36.190942Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\noutput_dir=\"lora-bart-base-fine-tuned-youtube-cnn-3\"\n\n# batch_size = 10\n# num_train_epochs = 8\n# Show the training loss with every epoch\n# logging_steps = len(tokenized_dataset[\"train\"]) // batch_size\nmodel_name = model_id.split(\"/\")[-1]\n\nargs = Seq2SeqTrainingArguments(\n    output_dir='./outputs',\n    eval_steps=100,\n    logging_steps=100,\n    warmup_steps=100,\n    evaluation_strategy=\"steps\",\n    report_to=\"all\",\n    log_level=\"debug\",\n    logging_dir='./logs',\n    learning_rate=1e-3,\n    per_device_train_batch_size=10,\n    per_device_eval_batch_size=10,\n    do_train=True,\n    do_eval=True,\n    weight_decay=0.05,\n    # save_total_limit=3,\n#     num_train_epochs=num_train_epochs,\n#     predict_with_generate=True,\n    gradient_accumulation_steps = 24,\n    max_steps=1000,\n    lr_scheduler_type=\"linear\",  # Linearly decrease after warmup\n#     push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:43.185983Z","iopub.execute_input":"2024-03-04T22:27:43.186356Z","iopub.status.idle":"2024-03-04T22:27:43.229736Z","shell.execute_reply.started":"2024-03-04T22:27:43.186327Z","shell.execute_reply":"2024-03-04T22:27:43.228720Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install nltk","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download(\"punkt\")\n\nfrom datasets import load_metric\nrouge_metric = load_metric(\"rouge\", trust_remote_code=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    # Decode generated summaries into text\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    # Decode reference summaries into text\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    # ROUGE expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n    # Compute ROUGE scores\n    result = rouge_score.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n    # Extract the scores\n    result = {key: value * 100 for key, value in result.items()}\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:40.115982Z","iopub.execute_input":"2024-03-04T22:27:40.116834Z","iopub.status.idle":"2024-03-04T22:27:40.120894Z","shell.execute_reply.started":"2024-03-04T22:27:40.116807Z","shell.execute_reply":"2024-03-04T22:27:40.120021Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n#     compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:47.421025Z","iopub.execute_input":"2024-03-04T22:27:47.421890Z","iopub.status.idle":"2024-03-04T22:27:47.679439Z","shell.execute_reply.started":"2024-03-04T22:27:47.421854Z","shell.execute_reply":"2024-03-04T22:27:47.678579Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train() ","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:27:49.197209Z","iopub.execute_input":"2024-03-04T22:27:49.197838Z","iopub.status.idle":"2024-03-05T03:48:52.910138Z","shell.execute_reply.started":"2024-03-04T22:27:49.197808Z","shell.execute_reply":"2024-03-05T03:48:52.909350Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 10\n***** Running training *****\n  Num examples = 21,730\n  Num Epochs = 12\n  Instantaneous batch size per device = 10\n  Total train batch size (w. parallel, distributed & accumulation) = 240\n  Gradient Accumulation steps = 24\n  Total optimization steps = 1,000\n  Number of trainable parameters = 995,328\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 5:20:44, Epoch 11/12]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>3.030400</td>\n      <td>2.097836</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.416300</td>\n      <td>2.011829</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.336900</td>\n      <td>1.988548</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.289800</td>\n      <td>1.969511</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>2.254300</td>\n      <td>1.963721</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.235000</td>\n      <td>1.948270</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>2.213200</td>\n      <td>1.942316</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>2.199000</td>\n      <td>1.935334</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>2.183300</td>\n      <td>1.926417</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.178700</td>\n      <td>1.928086</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 2750\n  Batch size = 10\n***** Running Evaluation *****\n  Num examples = 2750\n  Batch size = 10\n***** Running Evaluation *****\n  Num examples = 2750\n  Batch size = 10\n***** Running Evaluation *****\n  Num examples = 2750\n  Batch size = 10\n***** Running Evaluation *****\n  Num examples = 2750\n  Batch size = 10\nSaving model checkpoint to ./outputs/tmp-checkpoint-500\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\nModel config BartConfig {\n  \"_name_or_path\": \"bart-base\",\n  \"activation_dropout\": 0.1,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartModel\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.1,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 768,\n  \"decoder_attention_heads\": 12,\n  \"decoder_ffn_dim\": 3072,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 12,\n  \"encoder_ffn_dim\": 3072,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_position_embeddings\": 1024,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 1,\n  \"scale_embedding\": false,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"length_penalty\": 1.0,\n      \"max_length\": 128,\n      \"min_length\": 12,\n      \"num_beams\": 4\n    },\n    \"summarization_cnn\": {\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"num_beams\": 4\n    },\n    \"summarization_xsum\": {\n      \"length_penalty\": 1.0,\n      \"max_length\": 62,\n      \"min_length\": 11,\n      \"num_beams\": 6\n    }\n  },\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.38.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\ntokenizer config file saved in ./outputs/tmp-checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in ./outputs/tmp-checkpoint-500/special_tokens_map.json\n***** Running Evaluation *****\n  Num examples = 2750\n  Batch size = 10\n***** Running Evaluation *****\n  Num examples = 2750\n  Batch size = 10\n***** Running Evaluation *****\n  Num examples = 2750\n  Batch size = 10\n***** Running Evaluation *****\n  Num examples = 2750\n  Batch size = 10\n***** Running Evaluation *****\n  Num examples = 2750\n  Batch size = 10\nSaving model checkpoint to ./outputs/tmp-checkpoint-1000\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\nModel config BartConfig {\n  \"_name_or_path\": \"bart-base\",\n  \"activation_dropout\": 0.1,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartModel\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.1,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 768,\n  \"decoder_attention_heads\": 12,\n  \"decoder_ffn_dim\": 3072,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 12,\n  \"encoder_ffn_dim\": 3072,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_position_embeddings\": 1024,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 1,\n  \"scale_embedding\": false,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"length_penalty\": 1.0,\n      \"max_length\": 128,\n      \"min_length\": 12,\n      \"num_beams\": 4\n    },\n    \"summarization_cnn\": {\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"num_beams\": 4\n    },\n    \"summarization_xsum\": {\n      \"length_penalty\": 1.0,\n      \"max_length\": 62,\n      \"min_length\": 11,\n      \"num_beams\": 6\n    }\n  },\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.38.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\ntokenizer config file saved in ./outputs/tmp-checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in ./outputs/tmp-checkpoint-1000/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1000, training_loss=2.3336665344238283, metrics={'train_runtime': 19263.4024, 'train_samples_per_second': 12.459, 'train_steps_per_second': 0.052, 'total_flos': 1.477580515264512e+17, 'train_loss': 2.3336665344238283, 'epoch': 11.04})"},"metadata":{}}]},{"cell_type":"code","source":"# to hugging face\nmodel_name = \"IT-General-Data-Summarization\"\nHUGGING_FACE_USER_NAME = \"mou3az\"\n\nL_model.push_to_hub(f\"{HUGGING_FACE_USER_NAME}/{model_name}\", token='')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_directory = \"LORA tunning of facebook-bart\"\nmodel.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:49:41.289182Z","iopub.execute_input":"2024-03-05T03:49:41.289535Z","iopub.status.idle":"2024-03-05T03:49:41.587213Z","shell.execute_reply.started":"2024-03-05T03:49:41.289508Z","shell.execute_reply":"2024-03-05T03:49:41.586335Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\nModel config BartConfig {\n  \"_name_or_path\": \"bart-base\",\n  \"activation_dropout\": 0.1,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartModel\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.1,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 768,\n  \"decoder_attention_heads\": 12,\n  \"decoder_ffn_dim\": 3072,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 12,\n  \"encoder_ffn_dim\": 3072,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_position_embeddings\": 1024,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 1,\n  \"scale_embedding\": false,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"length_penalty\": 1.0,\n      \"max_length\": 128,\n      \"min_length\": 12,\n      \"num_beams\": 4\n    },\n    \"summarization_cnn\": {\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"num_beams\": 4\n    },\n    \"summarization_xsum\": {\n      \"length_penalty\": 1.0,\n      \"max_length\": 62,\n      \"min_length\": 11,\n      \"num_beams\": 6\n    }\n  },\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.38.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\ntokenizer config file saved in LORA tunning of facebook-bart/tokenizer_config.json\nSpecial tokens file saved in LORA tunning of facebook-bart/special_tokens_map.json\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"('LORA tunning of facebook-bart/tokenizer_config.json',\n 'LORA tunning of facebook-bart/special_tokens_map.json',\n 'LORA tunning of facebook-bart/vocab.json',\n 'LORA tunning of facebook-bart/merges.txt',\n 'LORA tunning of facebook-bart/added_tokens.json',\n 'LORA tunning of facebook-bart/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"device = next(model.parameters()).device\n\n# Function to calculate ROUGE scores\ndef calculate_rouge(predictions, references):\n    rouge_results = rouge_metric.compute(predictions=predictions, references=references)\n    return rouge_results\n\n# Function to generate predictions\ndef generate_predictions(model, dataset):\n    # Perform inference\n    predictions = []\n    for example in dataset:\n        input_ids = tokenizer(example[\"text\"], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n        outputs = model.generate(**input_ids, early_stopping=True, num_beams=7, num_return_sequences=1, max_new_tokens=1024, no_repeat_ngram_size= 3)\n        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        predictions.append(prediction)\n    return predictions\n\n# Run inference\npredictions = generate_predictions(model, dataset[\"validation\"])\n\n# Compute ROUGE scores\nreferences = [example[\"summary\"] for example in dataset[\"validation\"]]\nrouge_scores = calculate_rouge(predictions, references)","metadata":{"execution":{"iopub.status.idle":"2024-03-05T06:48:50.140961Z","shell.execute_reply.started":"2024-03-05T05:54:45.324558Z","shell.execute_reply":"2024-03-05T06:48:50.139951Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"rouge_scores","metadata":{"execution":{"iopub.status.busy":"2024-03-05T06:49:29.194187Z","iopub.execute_input":"2024-03-05T06:49:29.194547Z","iopub.status.idle":"2024-03-05T06:49:29.200613Z","shell.execute_reply.started":"2024-03-05T06:49:29.194519Z","shell.execute_reply":"2024-03-05T06:49:29.199681Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"{'rouge1': AggregateScore(low=Score(precision=0.40111303779854607, recall=0.4565258921607348, fmeasure=0.4134774428450369), mid=Score(precision=0.40633874815680177, recall=0.46167383600180967, fmeasure=0.4179207840737956), high=Score(precision=0.41175327050160954, recall=0.4666723737653531, fmeasure=0.4226458234342272)),\n 'rouge2': AggregateScore(low=Score(precision=0.17582252129306328, recall=0.19864898571559128, fmeasure=0.18034843739795808), mid=Score(precision=0.1799177561628951, recall=0.2033712470378194, fmeasure=0.18437582253998974), high=Score(precision=0.1847914909653636, recall=0.20802975609737862, fmeasure=0.18880338211459904)),\n 'rougeL': AggregateScore(low=Score(precision=0.2687003251090096, recall=0.30795493803091084, fmeasure=0.2776918205456754), mid=Score(precision=0.2730224673220921, recall=0.31254690446842437, fmeasure=0.2815639847993016), high=Score(precision=0.2772787127695215, recall=0.3169361864056118, fmeasure=0.28537912524233394)),\n 'rougeLsum': AggregateScore(low=Score(precision=0.3363166560052349, recall=0.38840324780910285, fmeasure=0.34902625504562906), mid=Score(precision=0.3413393813961342, recall=0.3934015037955896, fmeasure=0.3530592125789499), high=Score(precision=0.34643707820456887, recall=0.3985759767882486, fmeasure=0.35723385603791014))}"},"metadata":{}}]},{"cell_type":"code","source":"# rouge_1_f1 = 0.433\n# rouge_2_f1 = 0.191\n# rouge_l_f1 = 0.292\n# rouge_lsum_f1 = 0.365","metadata":{},"execution_count":null,"outputs":[]}]}